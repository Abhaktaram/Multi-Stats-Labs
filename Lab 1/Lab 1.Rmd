---
title: "Lab 1"
author: "Ananya Bhaktaram"
class: "Multilevel & Longitudinal Statistics"
date: "`r Sys.Date()`"
output: html_document
---

# Part A
Multivariate Gaussian (aka "normal" - it is not) distribution: the univariate Gaussian distribution can be extended to handle a vector of two ("bivariate") or more ("multivariate") random variables of length n.  In this case, the mean vector also has length n and the variance/covariance matrix is n x n  (n rows and n columns).  The n diagonal elements of the square covariance matrix contain the variances for the n individual random variable, and the off-diagonal elements are the covariances for each of the "n choose 2" (n(n-1)/2) possible pairs of random variables.

For instance, the multivariate Gaussian distribution for $\begin{pmatrix} Y_{i1} \\ Y_{i2} \\ Y_{i3} \end{pmatrix}$ is given by:

$$\begin{pmatrix} Y_{i1} \\ Y_{i2} \\ Y_{i3} \end{pmatrix} \sim MVN\left(\begin{pmatrix} \mu_1 \\ \mu_2 \\ \mu_3 \end{pmatrix}, \begin{pmatrix} \sigma_1^2 & \sigma_1\sigma_2\rho_{12} & \sigma_1\sigma_3\rho_{13} \\ \sigma_1\sigma_2\rho_{12} & \sigma_2^2 & \sigma_2\sigma_3\rho_{23} \\ \sigma_1\sigma_3\rho_{13} & \sigma_2\sigma_3\rho_{23} & \sigma_3^2 \end{pmatrix}\right)$$


### Question 1: 

What do the values μ_2 and 〖σ_2〗^2 represent? Hand draw the distribution of Y_i2 labeling the mean and standard deviation in your figure. (10 pts)

μ_2 is the population variable mean at Y_i2.

σ_2〗^2 is the populations variance at time Y_i2.

```{r}
## Visualization of Y_i2 distribution
library(ggplot2)

library(ggplot2)

# Set parameters
mu2 <- 5
sigma2 <- 2

# Create data frame
x <- seq(mu2 - 4*sigma2, mu2 + 4*sigma2, length.out = 1000)
df <- data.frame(x = x, y = dnorm(x, mu2, sigma2))

# Create plot
ggplot(df, aes(x = x, y = y)) +
  geom_line(color = "blue", size = 1) +
  geom_vline(xintercept = mu2, color = "red", linetype = "dashed", size = 1) +
  geom_vline(xintercept = c(mu2 - sigma2, mu2 + sigma2), 
             color = "green", linetype = "dotted") +
  annotate("text", x = mu2, y = 0.01, label = expression(mu[2]), 
           color = "red", size = 5) +
  annotate("text", x = mu2 - sigma2, y = 0.005, 
           label = expression(mu[2] - sigma[2]), color = "green", size = 3) +
  annotate("text", x = mu2 + sigma2, y = 0.005, 
           label = expression(mu[2] + sigma[2]), color = "green", size = 3) +
  labs(title = expression("Distribution of Y"[i2]),
       x = expression("Y"[i2]),
       y = "f(y)") +
  theme_minimal()
```

### Question 2:

What does the value σ_1 σ_3 ρ_13 represent? (10 pts)

The covariance between the first population mean and the third population mean, which is equivalent to SQRT Var (Yi1) SQRT  Var (Yi3) * Corr (Yi1Yi3).

### Question 3: 

Interpret the values ρ_12, ρ_13 and ρ_23? (10 pts)

ρ_12 represents the correlation between time point 1 and 2.

ρ_13 represents the correlation between time point 1 and 3.

ρ_23 represents the correlation between time point 2 and 3.

# Part B

Consider the multivariate Gaussian model for our application where, for each individual, we have 5 repeated measurements of the SF-36 mental health score at hospital discharge and then monthly for 4 months.  The parameters associated with this multivariate (n = 5) Gaussian distribution comprise: 5 means, 5 variances and (5×(5-1))/2=10 pairwise correlations.  

Let Y_(ij )be the SF-36 mental health score for subject i = 1, …, 100, at visit j = 1, 2, 3, 4, 5 corresponding to hospital discharge (j = 1), and subsequent monthly assessments (j = 2, 3, 4, 5). 

Assume the data for subject i are generated at random from a multivariate Gaussian distribution with: means 35, 38, 43, 49, 48 for j = 1, 2, 3, 4, 5;  equal variances over time of 100; and correlation ρjk for times j and k of ρ12 = 0.85, ρ13 = 0.80, ρ14 = 0.72, ρ15 = 0.69, ρ23 = 0.85, ρ24 = 0.80, ρ25 = 0.72, ρ34 = 0.85, ρ35 = 0.80, ρ45 = 0.85. 

### Question 4
In the space below, practice your understanding of the notation by writing out the multivariate (n=5) Gaussian distribution. (10 pts)

$$\begin{pmatrix} Y_{i1} \\ Y_{i2} \\ Y_{i3} \\ Y_{i4} \\ Y_{i5} \end{pmatrix}
\sim MVN\left(\begin{pmatrix} \ 35 \\ 38 \\ 43 \\ 39 \\ 48\end{pmatrix}, 
\begin{pmatrix}
1.00 & 0.85 & 0.80 & 0.72 & 0.69 \\
0.85 & 1.00 & 0.85 & 0.80 & 0.72 \\
0.80 & 0.85 & 1.00 & 0.85 & 0.80 \\
0.72 & 0.80 & 0.85 & 1.00 & 0.85 \\
0.69 & 0.72 & 0.80 & 0.85 & 1.00
\end{pmatrix}\right)$$
 
### Question 5:
Describe in a sentence or two the pattern you observe in the correlations for pairs of observations.  Use the "autocorrelation matrix" (ACM) above to obtain the "autocorrelation function "(ACF): \rho(u)=corr(Y_{ij\ },Y_{ij+u}),\ u=1,...,4. Briefly describe the approach/method you used to obtain the ACF from the ACM. Given your lay understanding of the SF-36 measure, how is nature likely to work to produce the ACF pattern you observe. (10 pts)

The pattern shown in the correlations generally decreases as the time gap increases, which is typical for longitudinal data as measurements that are closer to one another in time are more likely to be highly correlated.

The autocorrelation function measures the correlation between measurements separated by u time units: 
\rho(1) = the correlation between consecutive time points (lag 1)
\rho(2) = the correlation between time points that are 2 units apart (lag 2)
\rho(3) = the correlation between time points that are 3 units apart (lag 3)
\rho(4) = the correlation between time points that are 4 units apart (lag 4)

```{r}
## Calculating the autocorrelation function

# Read in correlation matrix
R <- matrix(c(
  1.00, 0.85, 0.80, 0.72, 0.69,
  0.85, 1.00, 0.85, 0.80, 0.72,
  0.80, 0.85, 1.00, 0.85, 0.80,
  0.72, 0.80, 0.85, 1.00, 0.85,
  0.69, 0.72, 0.80, 0.85, 1.00
), nrow = 5, byrow = TRUE)

# Simple function to extract autocorrelations
get_autocorr <- function(corr_matrix) {
  n <- nrow(corr_matrix)
  autocorr <- numeric(n-1)
  
  for(u in 1:(n-1)) {
    # Extract diagonal u positions above main diagonal
    autocorr[u] <- corr_matrix[1, 1+u]  # Since structure is stationary
  }
  
  return(autocorr)
}

# Calculate
rho <- get_autocorr(R)
names(rho) <- paste0("lag_", 1:4)
print(rho)
```
Because the correlation between any two time points only depends on their distance (the lag) not their absolute positions all correlations at the same lag are equal. Given that the the lags are symmetric the autocorrelation function is able to summarize the pattern between time points that are stored in the matrix. In this case, because the effects are stationary the correlations given by the ACF and the ACM are the same. 

For example, an interpretation of both the ACM and ACF would be the same. In this case, a Patient's mental health (SF-36 score) at discharge (Time 1) has a 0.85 correlation with their 1-month follow-up (Time 2). Similarly, because the distance between Time 2 and Time 3 is the same as that between Time 1 and Time 2 this tells us that a Patient's SF-36 score at their 1 month follow up (Time 2) has a 0.85 correlation with their SF-36 score at their 2-month follow-up (Time 3). Overall, we see that the correlation decreases as the lag (time between follow-ups) increases. For example, the patient's SF-36 score at discharge (Time 1) only has a 0.69 correlation with their score at 4-month follow-up (TIme 5).

# Part C: Simulating Multivariate Gaussian Data

### Question 6: 

Simulate 100 random draws from the multivariate Gaussian distribution for the SF-36 data whose true mean and covariance matrix is specified above (and in the code).  Report the first 5 draws in the space below. (10 pts)
```{r}
library(mvtnorm)
set.seed(02022022) # Important for reproducibility
mm <- c(35, 38, 43, 49, 48)
C <- matrix(c(1.00,0.85,0.80,0.72,0.69,
              0.85,1.00,0.85,0.80,0.72,
              0.80,0.85,1.00,0.85,0.80,
              0.72,0.80,0.85,1.00,0.85,
              0.69,0.72,0.80,0.85,1.00),
            nrow = 5) 
sigma <- C * 100
y <- rmvnorm(n=100, mean=mm, sigma=sigma)
id <- seq(1,100)
dat <- as.data.frame(cbind(y,id))
names(dat) <- c("y0","y1","y2","y3","y4","id")

head(dat, 5)

```

### Question 7: 
Display your simulated data using a spaghetti plot and a pairs plot. Calculate the mean and covariance matrix for your sample of n=100 simulated vectors. Use these plots and estimates to describe the patterns of potential scientific interest in the SF-36 data. (10 pts)

```{r}
# Load Libraries
library(tidyverse)
library(nlme)
library(mvtnorm)
library(joineR)
library (GGally)
```

```{r}
# Use your simulated SF-36 data (stored as dat)
# Convert to long format for analysis
df_long <- dat %>%
  pivot_longer(cols = y0:y4, 
               names_to = "time_point", 
               values_to = "SF36_score") %>%
  mutate(
    time_numeric = as.numeric(str_extract(time_point, "\\d+")),
    time_label = case_when(
      time_numeric == 0 ~ "Discharge",
      time_numeric == 1 ~ "Month 1", 
      time_numeric == 2 ~ "Month 2",
      time_numeric == 3 ~ "Month 3",
      time_numeric == 4 ~ "Month 4"
    )
  )

# Count unique subjects
n <- length(unique(df_long$id))
print(paste0("Number of subjects: ", n))

# Generate summaries for plotting
time.summaries <- df_long %>%
	group_by(time_numeric, time_label) %>%
	summarise(avgSF36 = mean(SF36_score),
	          sdSF36 = sd(SF36_score),
	          medSF36 = median(SF36_score),
	          q75SF36 = quantile(SF36_score, 0.75),
	          q25SF36 = quantile(SF36_score, 0.25),
	          .groups = 'drop')

print(time.summaries)
```

Visualize the sample means with a 95% confidence interval
```{r}
time.summaries %>%
	ggplot() +
	geom_point(aes(x = time_numeric, y = avgSF36), color = "red", size = 2) +
	geom_line(aes(x = time_numeric, y = avgSF36), color = "red", size = 1) +
  geom_pointrange(aes(x = time_numeric, y = avgSF36,
                      ymin = avgSF36 - 2*sdSF36/sqrt(n), 
                      ymax = avgSF36 + 2*sdSF36/sqrt(n))) +
	scale_x_continuous(breaks = 0:4, 
	                   labels = c("Discharge", "Month 1", "Month 2", "Month 3", "Month 4")) +
  scale_y_continuous(breaks = seq(30, 55, 5)) +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) +
	xlab("Time Point") +
	ylab("SF-36 Mental Health Score") +
	ggtitle("Average SF-36 Mental Health Scores Over Time (95% CI)")
```
Plot median and IQR
```{r}
time.summaries %>%
  ggplot() +
  geom_point(aes(x = time_numeric, y = medSF36), color = "blue", size = 2) +
  geom_line(aes(x = time_numeric, y = medSF36), color = "blue", size = 1) +
  geom_pointrange(aes(x = time_numeric, y = medSF36, 
                      ymin = q25SF36, ymax = q75SF36)) +
  scale_x_continuous(breaks = 0:4, 
                     labels = c("Discharge", "Month 1", "Month 2", "Month 3", "Month 4")) +
  scale_y_continuous(breaks = seq(30, 55, 5)) +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) +
  xlab("Time Point") +
  ylab("SF-36 Mental Health Score") +
  ggtitle("Median SF-36 Mental Health Scores Over Time (IQR)")
```
Look at distributions within each timepoint using boxplots
```{r}
df_long %>%
  ggplot() +
  geom_boxplot(aes(group = time_numeric, x = time_numeric, y = SF36_score)) +
  theme_bw() +
  scale_x_continuous(breaks = 0:4, 
                     labels = c("Discharge", "Month 1", "Month 2", "Month 3", "Month 4")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  xlab("Time Point") +
  ylab("SF-36 Mental Health Score") +
  geom_line(aes(group = id, x = time_numeric, y = SF36_score), 
            alpha = 0.3, colour = "grey") + 
  ggtitle("Individual SF-36 Mental Health Score Trajectories")
```
Pairs Plot
```{r}
pairs_dat <- subset(dat,select=-id)
pairs(pairs_dat)
```


Overlay mean trajectory to create final spaghetti plot
```{r}
ggplot(df_long) +
  geom_boxplot(aes(group = time_numeric, x = time_numeric, y = SF36_score)) +
	geom_line(aes(group = id, x = time_numeric, y = SF36_score), 
	          alpha = 0.3, colour = "grey") +
	theme_bw() +
	scale_x_continuous(breaks = 0:4, 
	                   labels = c("Discharge", "Month 1", "Month 2", "Month 3", "Month 4")) +
	theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
	xlab("Time Point") +
	ylab("SF-36 Mental Health Score") +
  geom_point(data = time.summaries, aes(x = time_numeric, y = avgSF36), 
             color = "red", size = 2) +
  geom_line(data = time.summaries, aes(x = time_numeric, y = avgSF36), #This is assing the mean trajctory line
            color = "red", size = 1.2) +
  geom_pointrange(data = time.summaries, 
                  aes(x = time_numeric, y = avgSF36,
                      ymin = avgSF36 - 2*sdSF36/sqrt(n), 
                      ymax = avgSF36 + 2*sdSF36/sqrt(n)),
                  color = "red") +
  ggtitle("SF-36 Mental Health Score Trajectories with Population Mean")
```
### Question 8: 
8. Calculate the autocorrelation matrix and autcorrelation function for your simulated data. Describe what else these estimates contribute to our understanding of the SF-36 data. (10 pts)

```{r}
# Calculate covariance matrix
cov_mat = dat %>% 
  select(-id) %>%
  cov() 

cov_mat[upper.tri(cov_mat)] = NA
cov_mat %>%
  as.data.frame()

```

Calculate autocorrelation of the residuals
```{r}
# The autocor command requires you to give: the residual, time variable, id variable
fit = gls(SF36_score~as.factor(time_numeric),df_long)
acf1 = ACF(fit,form= ~1|id)
acf1

# generate the lower bound
acf1 = acf1 %>%
	mutate(upper = 2 * 1 / sqrt(100 * (5-lag)))

# Make the plot
acf1 %>% 
  ggplot() + 
  geom_line(aes(x=lag, y=ACF))  +
  geom_line(aes(x=lag, y=upper), linetype=2) + 
  xlab("Lag (months)") +
  ylim(0,1.02) +
  theme_bw() +
  ggtitle("Autocorrelation Function for Simulated SF-36 Scores")
```
The solid line of this plot displays the autocorrelation function (ACF) for the simulated Sf-36 mental health data, while the dashed line shows the upper bound of a 95% confidence interval. Values above the line indicate significant autocorrelation, while values below this line could be attributed to random chance. This shows high autocorrelation at all lags, with an overall decreasing trend, meaning that measurements that are closer in time are more similar to one another than those that are more distant. All values are above the 95% confidence interval indicating that the temporal dependence displayed in the simulated data is statistically significant.

This tells us that current SF-36 scores strongly predict future scores, and that overall mental health improvements or declines tend to persist across time.

### Question 9: 
Now generate a new data set in a multilevel manner, producing a 100 x 5 matrix, call it Y. (10 pts) 

To generate each row, 5x1 vectors $Y_i=\left(\begin{matrix}Y_{i1}&Y_{i2}&Y_{i3}&Y_{i4}&Y_{i5}\\\end{matrix}\right)$ for each person i=1,\ldots,100, we use the equation

$Y_{ij}\ =\ m_j\ +\ b_i\ +\ e_{ij}\ \ \ \ j=1,\ldots,5;i=1,\ldots,100$

where m_j is the mean value for the\ jth random variable common to all 100 people (no subscript i) (we will use $m=\left(\begin{matrix}35&38&43&49&48\\\end{matrix}\right)$ from above), b_i is a scalar "random  intercept", common to all 5 observations for person i, but different among people, and e_{ij} is a residual or "error" specific to observation j for person i.  We assume that: (1) the 100 b_i’s are independent and identically distributed ("IID") draws from a Gaussian distribution with mean 0 and variance 120; (2) the 500=100x5 e_{ij}’s are iid Gaussian with mean 0 and variance 100, and that (3) the b_i’s are independent of the e_{ij}’s.  

(1) generate a 100 x 5 matrix of e_{ij}’s by drawing 100 realizations from a 5-dimensional Gaussian distribution with mean 0 and covariance matrix that is diagonal with 100 on the main diagonal and 0 off the diagonal. Because the covariances are all 0 and the data are multivariate Gaussian, the repeated observations for an individual are independent of one another. 
(2) generate a vector of 100 independent univariate Gaussian variates with mean zero and variance 120. These values are the 100 "random intercepts", one for each person (row). 
(3) Create the 100 x 5 matrix of Y values by adding the mean vector (repeated over rows), random intercepts (repeated over columns), and the random errors matrix. 

# Simulate new data
```{r}
library(mvtnorm)

# Define population parameters
set.seed(02022022) # Important for reproducibility

# Population means (m_j) are the same for all 100 people
mm <- c(35, 38, 43, 49, 48) 
cat("Population means m_j:", mm, "\n")

# Model parameters
n_subjects <- 100 # i = 1, 2, ... 100 people
n_times <- 5 # j = 1,2,3,4,5  (5 time points)

# Establish Variance parameters
var_b <- 120 # Variance of random intercepts b1
var_e <- 100 # Variance of random errors e_ij
cat("Random intercept variance (var_b):", var_b, "\n")
cat("Random error variance (var_e):", var_e, "\n\n")
```

Generate Random Intercepts
```{r}
cat("Generating random intercepts b_i...\n")

# Generate 100 random intercepts (one per person)
b_i <- rnorm(n = n_subjects, mean = 0, sd = sqrt(var_b))

cat("First 10 random intercepts:", round(b_i[1:10], 2), "\n")
cat("Sample mean of b_i (should ≈ 0):", round(mean(b_i), 2), "\n")
cat("Sample variance of b_i (should ≈ 120):", round(var(b_i), 2), "\n\n")
```

Generate Random Errors Matrix
```{r}
# Generate 500 = 100×5 independent random errors
e_ij <- matrix(rnorm(n = n_subjects * n_times, mean = 0, sd = sqrt(var_e)), 
               nrow = n_subjects, ncol = n_times)

cat("Error matrix dimensions:", dim(e_ij), "\n")
cat("Sample mean of all e_ij (should ≈ 0):", round(mean(e_ij), 2), "\n")
cat("Sample variance of all e_ij (should ≈ 100):", round(var(as.vector(e_ij)), 2), "\n")

cat("Sample correlation between person 1 and person 2 errors:", 
    round(cor(e_ij[1, ], e_ij[2, ]), 3), "\n")
```
Create Component Matrices for the Model
```{r}
# Mean matrix: replicate m_j for each person (100 identical rows)
m_matrix <- matrix(rep(mm, n_subjects), 
                   nrow = n_subjects, ncol = n_times, byrow = TRUE)

# Random intercept matrix: replicate each b_i across all time points
b_matrix <- matrix(rep(b_i, n_times), 
                   nrow = n_subjects, ncol = n_times, byrow = FALSE)

cat("Mean matrix (first 3 rows):\n")
print(m_matrix[1:3, ])
cat("Random intercept matrix (first 3 rows):\n")
print(round(b_matrix[1:3, ], 2))
```
Creation of simulated Y matrix by adding all of the components
```{r}
# Create Y matrix by adding all components
Y <- m_matrix + b_matrix + e_ij

cat("Simulated Y matrix dimensions:", dim(Y), "\n")
cat("First 5 subjects' Y values:\n")
print(round(Y[1:5, ], 2))
```
Add subject ID's to Simulated Y Matrix
```{r}
# Create subject IDs
id <- seq(1, 100)

# Add IDs directly to Y matrix as a new column
Y <- cbind(Y, id)

# Add column names to the Y matrix
colnames(Y) <- c("y0", "y1", "y2", "y3", "y4", "id")

cat("First 5 rows of Y matrix:\n")
print(round(Y[1:5, ], 2))

cat("Structure of Y matrix:\n")
str(Y)
```

### Question 10: 
Again, display your simulated data using a spaghetti plot and pairs plot. (10 pts) 

Convert Y matrix to long format in order to plot
```{r}
# Convert Y matrix to long format for ggplot
Y_long <- Y %>%
  as.data.frame() %>%
  pivot_longer(cols = y0:y4, 
               names_to = "time_point", 
               values_to = "SF36_score") %>%
  mutate(
    time_numeric = as.numeric(str_extract(time_point, "\\d+")),
    time_label = case_when(
      time_numeric == 0 ~ "Discharge",
      time_numeric == 1 ~ "Month 1", 
      time_numeric == 2 ~ "Month 2",
      time_numeric == 3 ~ "Month 3",
      time_numeric == 4 ~ "Month 4"
    )
  )
```
Calculate summary statistics for the new data
```{r}
n <- length(unique(Y_long$id))  # Number of subjects (should be 100)

time.summaries <- Y_long %>%
	group_by(time_numeric, time_label) %>%
	summarise(avgSF36 = mean(SF36_score),
	          sdSF36 = sd(SF36_score),
	          medSF36 = median(SF36_score),
	          q75SF36 = quantile(SF36_score, 0.75),
	          q25SF36 = quantile(SF36_score, 0.25),
	          .groups = 'drop')

cat("Summary statistics for new simulated data:\n")
print(time.summaries)
```

Create the spaghetti plot
```{r}
ggplot(Y_long) +
  geom_boxplot(aes(group = time_numeric, x = time_numeric, y = SF36_score)) +
	geom_line(aes(group = id, x = time_numeric, y = SF36_score), 
	          alpha = 0.3, colour = "grey") +
	theme_bw() +
	scale_x_continuous(breaks = 0:4, 
	                   labels = c("Discharge", "Month 1", "Month 2", "Month 3", "Month 4")) +
	theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
	xlab("Time Point") +
	ylab("SF-36 Mental Health Score") +
  geom_point(data = time.summaries, aes(x = time_numeric, y = avgSF36), 
             color = "red", size = 2) +
  geom_line(data = time.summaries, aes(x = time_numeric, y = avgSF36), 
            color = "red", size = 1.2) +
  geom_pointrange(data = time.summaries, 
                  aes(x = time_numeric, y = avgSF36,
                      ymin = avgSF36 - 2*sdSF36/sqrt(n), 
                      ymax = avgSF36 + 2*sdSF36/sqrt(n)),
                  color = "red") +
  ggtitle("SF-36 Mental Health Score Trajectories (Random Intercept Model)")
```


### Question 11: 
Calculate the autocorrelation matrix and autocorrelation function for these simulated data. (10 pts) 

Calculate covariance matrix for the Y 
```{r}
# Convert Y_long data frame into a wide dataframe
Y_wide <- Y_long %>%
  select(id, time_point, SF36_score) %>%
  pivot_wider(names_from = time_point, 
              values_from = SF36_score)

# Calculate covariance matrix
cov_mat <- Y_wide %>% 
  select(-id) %>%
  cov() 

cov_mat[upper.tri(cov_mat)] = NA
cov_mat %>%
  as.data.frame()
```

Calculate autocorrelation of the residuals
```{r}
# The autocor command requires you to give: the residual, time variable, id variable
fit = gls(SF36_score~as.factor(time_numeric),Y_long)
acf1 = ACF(fit,form= ~1|id)
acf1

# generate the lower bound
acf1 = acf1 %>%
	mutate(upper = 2 * 1 / sqrt(100 * (5-lag)))

# Make the plot
acf1 %>% 
  ggplot() + 
  geom_line(aes(x=lag, y=ACF))  +
  geom_line(aes(x=lag, y=upper), linetype=2) + 
  xlab("Lag (months)") +
  ylim(0,1.02) +
  theme_bw() +
  ggtitle("Autocorrelation Function for Simulated SF-36 Scores")
```

### Question 12: 
Using the SF-36 example, explain the scientific meaning of the means, random intercepts, variance of the random intercepts, residuals, and variance of the residuals. (10 pts)  

The means represent the average trajectory of the SF-36 score across the entire population at that specific time lag. 

The random intercepts represent the baseline value or starting point for each individual. In this case, its each individual person's SF-36 score at baseline.
 
The variance of the random intercepts tells us the degree of heterogeneity we anticipate around the mean function. In this case, how far we expect an individual's specific variance, in regards to their SF-36 score, to deviate from the mean. 

The residuals for each individual observation represent the unexplained error within each subject over time.

The variance of the residuals measures the unexplained variability in the SF-36 scores after accounting for the individual and time-varying effects. 

```{r}
# R Session Information
options(width = 120)
sessioninfo::session_info()
```

